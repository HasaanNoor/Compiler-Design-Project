{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyNAJWT1winOZgLNyOm+dFgA",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/HasaanNoor/Compiler-Design-Project/blob/main/Lexical_Analyser.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "IaxpiXLMpa6d",
        "outputId": "1ba68315-c396-4f9d-b52a-b328b047da12"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "('Var: ', 'x')\n",
            "('Assignment: ', '=')\n",
            "('Number: ', '42')\n",
            "('Delimiter: ', ';')\n",
            "('Var: ', 'y')\n",
            "('Assignment: ', '=')\n",
            "('Var: ', 'x')\n",
            "('Operator: ', '*')\n",
            "('Number: ', '2')\n",
            "('Delimiter: ', ';')\n"
          ]
        }
      ],
      "source": [
        "import re\n",
        "\n",
        "def tokenize(input_string):\n",
        "    patterns = [\n",
        "        (r'\\s+', None, 0),  # Ignore whitespace\n",
        "        (r'//.*', None, 0),  # Ignore single-line comments\n",
        "        (r'/\\*.*?\\*/', None, re.DOTALL),  # Ignore multi-line comments\n",
        "        (r'\\+', 'Operator: ', 0),\n",
        "        (r'-', 'Operator: ', 0),\n",
        "        (r'\\*', 'Operator: ', 0),\n",
        "        (r'/', 'Operator: ', 0),\n",
        "        (r'\\^', 'Operator: ', 0),\n",
        "        (r'=', 'Assignment: ', 0),\n",
        "        (r'%', 'Operator: ', 0),\n",
        "        (r';', 'Delimiter: ', 0),\n",
        "        (r'User\\s+In:', 'User In: ', 0),\n",
        "        (r'Print:', 'Print: ', 0),\n",
        "        (r'[a-zA-Z_][a-zA-Z0-9_]*', 'Var: ', 0),\n",
        "        (r'\\d+(\\.\\d*)?', 'Number: ', 0),\n",
        "        (r'\\(', 'Left Paren: ', 0),\n",
        "        (r'\\)', 'Right Paren: ', 0)\n",
        "    ]\n",
        "    tokens = []\n",
        "    input_string = input_string.strip()\n",
        "\n",
        "    while input_string:\n",
        "        match = False\n",
        "        for pattern, token_type, flags in patterns:\n",
        "            regex_match = re.match(pattern, input_string, flags)\n",
        "            if regex_match:\n",
        "                match = True\n",
        "                if token_type:  # If not None\n",
        "                    tokens.append((token_type, regex_match.group(0)))\n",
        "                input_string = input_string[regex_match.end():].strip()\n",
        "                break\n",
        "        if not match:\n",
        "            raise ValueError(f\"Invalid token at: '{input_string}'\")\n",
        "    return tokens\n",
        "\n",
        "# Example usage\n",
        "code = \"x = 42; // Example comment\\ny = x * 2;\"\n",
        "try:\n",
        "    tokens = tokenize(code)\n",
        "    for token in tokens:\n",
        "        print(token)\n",
        "except ValueError as e:\n",
        "    print(e)"
      ]
    }
  ]
}